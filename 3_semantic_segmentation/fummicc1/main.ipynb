{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from network.pspnet import PSPNet\n",
    "%matplotlib inline\n",
    "# パッケージのimport\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期設定\n",
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import VOCDataset\n",
    "from make_datapath_list import make_datapath_list\n",
    "from data_transform import DataTransform\n",
    "\n",
    "# 動作確認 ファイルパスのリストを取得\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
    "    rootpath=rootpath\n",
    ")\n",
    "\n",
    "print(train_img_list[0])\n",
    "print(train_anno_list[0])\n",
    "\n",
    "# 動作確認\n",
    "# (RGB)の色の平均値と標準偏差\n",
    "color_mean = (0.485, 0.456, 0.406)\n",
    "color_std = (0.229, 0.224, 0.225)\n",
    "\n",
    "# データセット作成\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(\n",
    "    input_size=475, color_mean=color_mean, color_std=color_std))\n",
    "\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n",
    "    input_size=475, color_mean=color_mean, color_std=color_std))\n",
    "\n",
    "# データの取り出し例\n",
    "print(val_dataset.__getitem__(0)[0].shape)\n",
    "print(val_dataset.__getitem__(0)[1].shape)\n",
    "print(val_dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実行するたびに変わります\n",
    "\n",
    "# 画像データの読み込み\n",
    "index = 0\n",
    "imges, anno_class_imges = train_dataset.__getitem__(index)\n",
    "\n",
    "# 画像の表示\n",
    "img_val = imges\n",
    "img_val = img_val.numpy().transpose((1, 2, 0))\n",
    "plt.imshow(img_val)\n",
    "plt.show()\n",
    "\n",
    "# アノテーション画像の表示\n",
    "anno_file_path = train_anno_list[0]\n",
    "anno_class_img = Image.open(anno_file_path)   # [高さ][幅][色RGB]\n",
    "p_palette = anno_class_img.getpalette()\n",
    "\n",
    "anno_class_img_val = anno_class_imges.numpy()\n",
    "anno_class_img_val = Image.fromarray(np.uint8(anno_class_img_val), mode=\"P\")\n",
    "anno_class_img_val.putpalette(p_palette)\n",
    "plt.imshow(anno_class_img_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像データの読み込み\n",
    "index = 0\n",
    "imges, anno_class_imges = val_dataset.__getitem__(index)\n",
    "\n",
    "# 画像の表示\n",
    "img_val = imges\n",
    "img_val = img_val.numpy().transpose((1, 2, 0))\n",
    "plt.imshow(img_val)\n",
    "plt.show()\n",
    "\n",
    "# アノテーション画像の表示\n",
    "anno_file_path = train_anno_list[0]\n",
    "anno_class_img = Image.open(anno_file_path)   # [高さ][幅][色RGB]\n",
    "p_palette = anno_class_img.getpalette()\n",
    "\n",
    "anno_class_img_val = anno_class_imges.numpy()\n",
    "anno_class_img_val = Image.fromarray(np.uint8(anno_class_img_val), mode=\"P\")\n",
    "anno_class_img_val.putpalette(p_palette)\n",
    "plt.imshow(anno_class_img_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "net = PSPNet(n_classes=21)\n",
    "net\n",
    "batch_size = 2\n",
    "dummy_img = torch.rand(batch_size, 3, 475, 475)\n",
    "out = net(dummy_img)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_datapath_list import make_datapath_list\n",
    "from dataset import VOCDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ファイルパスリスト作成\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
    "    rootpath=rootpath)\n",
    "\n",
    "# Dataset作成\n",
    "# (RGB)の色の平均値と標準偏差\n",
    "color_mean = (0.485, 0.456, 0.406)\n",
    "color_std = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(\n",
    "    input_size=475, color_mean=color_mean, color_std=color_std))\n",
    "\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n",
    "    input_size=475, color_mean=color_mean, color_std=color_std))\n",
    "\n",
    "# DataLoader作成\n",
    "batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 辞書型変数にまとめる\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network.pspnet import PSPNet\n",
    "\n",
    "# ファインチューニングでPSPNetを作成\n",
    "# ADE20Kデータセットの学習済みモデルを使用、ADE20Kはクラス数が150です\n",
    "net = PSPNet(n_classes=150)\n",
    "\n",
    "# ADE20K学習済みパラメータをロード\n",
    "state_dict = torch.load(\"weights/pspnet50_ADE20K.pth\")\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "# 分類用の畳み込み層を、出力数21のものにつけかえる\n",
    "n_classes = 21\n",
    "net.decode_feature.classification = nn.Conv2d(\n",
    "    in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "net.aux.classification = nn.Conv2d(\n",
    "    in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "# 付け替えた畳み込み層を初期化する。活性化関数がシグモイド関数なのでXavierを使用する。\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:  # バイアス項がある場合\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "net.decode_feature.classification.apply(weights_init)\n",
    "net.aux.classification.apply(weights_init)\n",
    "\n",
    "\n",
    "print('ネットワーク設定完了：学習済みの重みをロードしました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network.psploss import PSPLoss\n",
    "criterion = PSPLoss(aux_weight=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from network.lr_scheduler import lambda_epoch\n",
    "from train import train_model\n",
    "\n",
    "optimizer = optim.SGD([\n",
    "    {\n",
    "        \"params\": net.feature_conv.parameters(), \"lr\": 1e-3\n",
    "    },\n",
    "    {\n",
    "        \"params\": net.feature_res_1.parameters(), \"lr\": 1e-3\n",
    "    },\n",
    "    {\n",
    "        \"params\": net.feature_res_2.parameters(), \"lr\": 1e-3\n",
    "    },\n",
    "    {\n",
    "        \"params\": net.feature_dilated_res_1.parameters(), \"lr\": 1e-3\n",
    "    },\n",
    "    {\n",
    "        \"params\": net.feature_dilated_res_2.parameters(), \"lr\": 1e-3\n",
    "    },\n",
    "    {\n",
    "        \"params\": net.pyramid_pooling.parameters(), \"lr\": 1e-3\n",
    "    },\n",
    "    {\n",
    "        \"params\": net.decode_feature.parameters(), \"lr\": 1e-2\n",
    "    },\n",
    "    {\n",
    "        \"params\": net.aux.parameters(), \"lr\": 1e-2\n",
    "    },\n",
    "], momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_epoch)\n",
    "num_epochs = 30\n",
    "train_model(\n",
    "    net,\n",
    "    dataloaders_dict,\n",
    "    criterion,\n",
    "    scheduler,\n",
    "    optimizer,\n",
    "    num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1727bab112b22306f9cef3414203d9ee217fe754856919e0464a6b3f3b549ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
